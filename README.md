### **APS Failure Prediction with Imbalanced Data Techniques**  
**Author:** Aditya Dutta  
**Date:** Oct 2024 - Nov 2024  
**Technologies:** Python, SQL, Random Forest, XGBoost, SMOTE  

---

## **Project Overview**  
This project focuses on **predicting Air Pressure System (APS) failures** in Scania trucks using machine learning techniques, addressing **severe class imbalance** in the dataset. The key methods include **SMOTE for oversampling**, **Random Forests**, and **XGBoost** for classification, along with **hyperparameter tuning and feature selection**.

---

## **Dataset**  
The dataset originates from the **APS Failure at Scania Trucks** dataset available at:  
ğŸ”— [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks)  

- **60,000 training samples** (1,000 positive, 59,000 negative)  
- **16,000 test samples** (375 positive, 15,625 negative)  
- **171 numerical features**, including missing values  
- **Objective:** Classify APS failures (1) vs. non-failures (0)  

---

## **Methods & Techniques**  

### **1. Data Preprocessing & Feature Engineering**  
âœ” **Missing Data Handling** â€“ Mean imputation for missing values  
âœ” **Feature Selection** â€“ Coefficient of Variation (CV) used to select top features  
âœ” **Correlation Analysis** â€“ Heatmaps and scatterplots for feature importance  

### **2. Model Training**  
ğŸ“Œ **Random Forest Classifier**  
   - Initially trained **without compensation** for class imbalance  
   - **Out-of-Bag (OOB) error estimation**  
   - **Confusion matrix, ROC, and AUC analysis**  

ğŸ“Œ **XGBoost Classifier**  
   - **Hyperparameter tuning** using **GridSearchCV**  
   - Compared **uncompensated** and **SMOTE-enhanced** versions  

### **3. Handling Class Imbalance**  
ğŸ”¹ **Without Compensation:** Higher accuracy but poor recall for minority class  
ğŸ”¹ **With SMOTE:** Improved recall for APS failures (from **76% to 90%**), but slightly higher misclassification for non-failures  

---

## **Results & Findings**  

| Model                 | Accuracy | Recall (APS Failures) | ROC AUC |  
|----------------------|------------|---------------------|---------|  
| Random Forest (No Balancing)  | **99.2%**  | **56.6%** | **0.98** |  
| Random Forest (Balanced)  | **96.0%**  | **96.8%** | **0.99** |  
| XGBoost (No Balancing)  | **98.8%**  | **76.3%** | **0.99** |  
| **XGBoost + SMOTE** | **96.1%**  | **90.9%** | **0.99** âœ… |  

âœ” **SMOTE significantly improved recall for APS failures from 76% to 90%**  
âœ” **XGBoost with SMOTE provided the best balance between recall and accuracy**  

---

## **How to Run the Project**  
1ï¸âƒ£ Install dependencies:  
```bash
pip install pandas numpy scikit-learn xgboost imbalanced-learn matplotlib seaborn
```
2ï¸âƒ£ Download the dataset from [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks)  
3ï¸âƒ£ Run the **Jupyter Notebook** or execute the script:  
```bash
python aps_failure_prediction.py
```

---

## **Key Takeaways**  
ğŸ”¹ **Handling class imbalance is critical** â€“ SMOTE significantly boosts recall  
ğŸ”¹ **XGBoost outperforms Random Forest** with better handling of rare failures  
ğŸ”¹ **Hyperparameter tuning and feature selection improve model robustness**  

---

## **Future Improvements**  
ğŸš€ **Experiment with Deep Learning (LSTMs or CNNs)** for time-series APS failure data  
ğŸš€ **Ensemble techniques** (combining RF & XGBoost)  
ğŸš€ **Threshold tuning** to balance precision-recall trade-offs  

---

### ğŸ“Œ **Contact**  
For any questions or improvements, feel free to connect! ğŸš€  

---

This **README.md** provides clear documentation, making it **easy for anyone to understand and reproduce your work**. Let me know if you need any modifications! ğŸ˜Š
